# -*- encoding:utf-8 -*-
'''


爬虫项目

多线程的实现  网页的扩展  数据库的存储  规避反爬的手段

爬取内容的分类： 文字 ， 图片  ， 文件

需要的库 ：
scrapy

请求：requests

爬虫基本流程：
    1） 选取一批url
    2）将这些url放到待抓取队列里
    3）从待抓取队列中取出url，解析dns，并且得到主机ip，并将url对应的网址下载下来，存储进已下载的网页库中，此外将这些url放进已下载的url队列中
    4） 分析已抓取url队列中的url， 从已下载的网页数据中分析出其他url，并和已抓取的url进行比较去重，最后将去重过的url放到待下载队列中，从而进入下一个循环

'''

